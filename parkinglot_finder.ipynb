{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinglot Finder Walkthrough\n",
    "This is a jupyter notebook walkthrough of the pipeline from a tif file to outputing a GeoJson of the parkinlots identified in the image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pickle\n",
    "from osgeo import gdal\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Input\n",
    "Place the file name in the quotations below. Note that the file must be a TIF file (meaning that the extension must be .tif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =  \"Vegas_333.tif\"\n",
    "\n",
    "if file_name.__len__ () == 0 or file_name.rfind (\".tif\") == -1:\n",
    "    raise EnvironmentError (\"Input file must be a TIF image, got: \" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Here `MODEL_NAME` should be changed to the name of the inference graph. Additionally, you should change `PATH_TO_LABELS` to the appropriate object-detection.pbtxt file and adjust `NUM_CLASSES` to represent the number of classes your model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'parking_lot_inference_graph'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('/home/thomas/Documents/SatImageParkingLotFinder/training', 'object-detection.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "This creates the label map that maps the numeric output to a specific label so since we have only once class it will map `1` to `parking lot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = ''\n",
    "image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, file_name.replace('tif','jpeg'))\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (24, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "\n",
    "GDAL_COMMAND    = u\"gdal_translate -scale_1 20 1463 -scale_2 114 1808 -scale_3 139 1256 -ot Byte -of\"\n",
    "file_type       = None\n",
    "\n",
    "file_types = [\"jpeg\", \"png\"]\n",
    "\n",
    "def convertTifTo (file_type, file_name):\n",
    "    u'''\n",
    "        Converts the given TIF file to the given file format.\n",
    "\n",
    "        @param  file_type   - The file format to convert to \\n\n",
    "        @param  file_name   - The TIF file to convert\n",
    "    '''\n",
    "    type_str = file_type.__str__ ()\n",
    "    conv_str = file_name.replace (u\"tif\", type_str)\n",
    "\n",
    "    os.system (GDAL_COMMAND + u\" \" + type_str.upper () + u\" \" + file_name + u\" \" + conv_str)\n",
    "    os.system (u\"rm \" + conv_str + u\".aux.xml\")\n",
    "\n",
    "def generateArguments ():\n",
    "    u'''\n",
    "        Parses the arguments passed to the script, and sets fields appropriately.\n",
    "\n",
    "        @throws EnvironmentError if an argument couldn't be understood (i.e. file format was not understood).\n",
    "    '''\n",
    "\n",
    "    from sys import argv\n",
    "    \n",
    "    args = {}\n",
    "    global file_name, file_type\n",
    "\n",
    "    while argv:\n",
    "        if argv [0][0] == u\"-\":\n",
    "            args [argv [0]] = argv [1]\n",
    "\n",
    "        argv = argv [1:]\n",
    "\n",
    "    if u\"-t\" in args:\n",
    "        arg = args [u\"-t\"]\n",
    "\n",
    "        for t in file_types:\n",
    "            if arg in t:\n",
    "                file_type = t\n",
    "                break\n",
    "\n",
    "        if file_type is None:\n",
    "            raise EnvironmentError (u\"Conversion file format was not recognized; Use: \" + File_Type.list ())\n",
    "    \n",
    "    else:\n",
    "        raise EnvironmentError (u\"A file format to convert to must be specified: -t \" + File_Type.list ())\n",
    "\n",
    "    if u\"-f\" in args:\n",
    "        file_name = args [u\"-f\"]\n",
    "\n",
    "def walkThrough (root = None):\n",
    "    u'''\n",
    "        Walks through the given directory and subdirectories, and converts any TIF files found to\n",
    "        the file format given as an argument to the script.\n",
    "\n",
    "        @param  root - The directory to begin the conversion at\n",
    "    '''\n",
    "\n",
    "    if root is None:\n",
    "        root = u\".\"\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk (root):\n",
    "        for file in filenames:\n",
    "            if file.endswith (u\".tif\"):\n",
    "                convertTifTo (file_type, os.path.join (dirpath, file))\n",
    "            \n",
    "convertTifTo (file_types [0], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from sys import argv\n",
    "import json\n",
    "\n",
    "# http://lxml.de/\n",
    "from lxml import etree\n",
    "\n",
    "# http://www.gdal.org/index.html\n",
    "from osgeo import gdal\n",
    "import io\n",
    "\n",
    "geojson = {\n",
    "    u\"type\" : u\"FeatureCollection\",\n",
    "    u\"name\" : file_name,\n",
    "    u\"features\" : []\n",
    "}\n",
    "\n",
    "def appendFeature (geojson, rect):\n",
    "    u'''\n",
    "        Appends a feature representing the given bounding box to the given\n",
    "        dictionary.\n",
    "\n",
    "        @param  geojson - The dictionary to append the new feature to \\n\n",
    "        @param  rect    - The list representing the bounding box (as x1, y1, x2, y2)\n",
    "    '''\n",
    "    geojson [u\"features\"].append ({\n",
    "        u\"type\": u\"Feature\",\n",
    "        u\"properties\": {},\n",
    "        u\"geometry\": {\n",
    "            u\"type\": u\"Polygon\",\n",
    "            u\"coordinates\": [ rect ]\n",
    "        }\n",
    "    })\n",
    "\n",
    "def convertCoordinates (dataset, x, y):\n",
    "    u'''\n",
    "        Converts the given pixel coordinates to geographical coordinates using the given\n",
    "        GDAL data set.\n",
    "\n",
    "        @param  dataset - The GDAL data set to extract latitude / longitude from \\n\n",
    "        @param  x       - The x pixel coordinate \\n\n",
    "        @param  y       - The y pixel coordinate \\n\n",
    "\n",
    "        @return A tuple containing the pixel coordinates converted to geographical coordinates\n",
    "    '''\n",
    "    origin = getOrigin (dataset)\n",
    "    pixel_size = getPixelSize (dataset)\n",
    "\n",
    "    return x * pixel_size [0] + origin [0], y * pixel_size [1] + origin [1]\n",
    "\n",
    "def generateArguments ():    \n",
    "    u'''\n",
    "        Parses the program arguments to determine what file should be converted.\n",
    "\n",
    "        @throws EnvironmentError if the argument couldn't be found / parsed\n",
    "    '''\n",
    "    global argv, file_name\n",
    "    args = {}\n",
    "\n",
    "    while argv:\n",
    "        if argv [0][0] == u\"-\":\n",
    "            args [argv [0]] = argv [1]\n",
    "\n",
    "        argv = argv [1:]\n",
    "\n",
    "    if u\"-f\" in args:\n",
    "        arg = args [u\"-f\"]\n",
    "        n = arg.rfind (u\".\")\n",
    "\n",
    "        file_name = arg [:n] if n >= 0 else arg\n",
    "\n",
    "    else:\n",
    "        raise EnvironmentError (u\"Filename must be specified with -f\")\n",
    "\n",
    "def getCoordinates (dataset, bndbox):\n",
    "    u'''\n",
    "        Gets and converts the coordinates of the bounding box contained in the given tree\n",
    "        element.\n",
    "\n",
    "        @param  dataset     - The GDAL data set to extract latitude / longitude from \\n\n",
    "        @param  robndbox    - The XML tree element that contains the bounding box (robndbox tag)\n",
    "\n",
    "        @return A list containing the converted coordinates of the bounding box\n",
    "    '''\n",
    "    width, height = getImageSize (dataset)\n",
    "    \n",
    "    xmin = float (bndbox [1]) * width\n",
    "    ymin = float (bndbox [0]) * height\n",
    "    xmax = float (bndbox [3]) * width\n",
    "    ymax = float (bndbox [2]) * height\n",
    "\n",
    "    return [convertCoordinates (dataset, xmin, ymin),\n",
    "        convertCoordinates (dataset, xmin, ymax),\n",
    "        convertCoordinates (dataset, xmax, ymax),\n",
    "        convertCoordinates (dataset, xmax, ymin),\n",
    "        convertCoordinates (dataset, xmin, ymin)]\n",
    "\n",
    "def getImageSize (dataset):\n",
    "    return dataset.RasterXSize, dataset.RasterYSize\n",
    "\n",
    "def getOrigin (dataset):\n",
    "    u'''\n",
    "        Returns the origin of the given GDAL data set.\n",
    "\n",
    "        @param  dataset - The GDAL data set to get the origin (geographical coordinates) of\n",
    "\n",
    "        @return A tuple containing the x and y geographical coordinates of the origin\n",
    "    '''\n",
    "    geotransform = dataset.GetGeoTransform ()\n",
    "    return geotransform [0], geotransform [3]\n",
    "\n",
    "def getPixelSize (dataset):\n",
    "    u'''\n",
    "        Returns the pixel size of each pixel in the given GDAL data set.\n",
    "\n",
    "        @param  dataset - The GDAL data set to get the pixel size of\n",
    "\n",
    "        @return A tuple containing the x and y pixel sizes\n",
    "    '''\n",
    "    geotransform = dataset.GetGeoTransform ()\n",
    "    return geotransform [1], geotransform [5]\n",
    "\n",
    "def convertBoundingBox (box, dataset):\n",
    "    appendFeature (geojson, getCoordinates (dataset, box))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image = Image.open(image_path)\n",
    "# the array based representation of the image will be used later in order to prepare the\n",
    "# result image with boxes and labels on it.\n",
    "image_np = load_image_into_numpy_array(image)\n",
    "# Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "# Actual detection.\n",
    "\n",
    "data = gdal.Open (file_name, gdal.GA_ReadOnly)\n",
    "output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "for i in range(0, output_dict['detection_boxes'].shape[0]):\n",
    "    #print(output_dict['detection_scores'][i]\n",
    "    if output_dict['detection_scores'][i] > 0.8:\n",
    "            #print(output_dict['detection_scores'][i])\n",
    "            convertBoundingBox (output_dict['detection_boxes'][i], data)\n",
    "              \n",
    "\n",
    "with io.open(file_name.replace ('tif', 'geojson'),'w',encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(unicode(json.dumps(geojson, ensure_ascii=False)))\n",
    "   # Visualization of the results of a detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
